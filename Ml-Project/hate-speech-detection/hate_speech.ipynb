{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca69b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv('hateDetection_train.csv')\n",
    "tweet_df.head()\n",
    "tweet_df.info()\n",
    "# printing random tweets \n",
    "print(tweet_df['tweet'].iloc[0],\"\\n\")\n",
    "print(tweet_df['tweet'].iloc[1],\"\\n\")\n",
    "print(tweet_df['tweet'].iloc[2],\"\\n\")\n",
    "print(tweet_df['tweet'].iloc[3],\"\\n\")\n",
    "print(tweet_df['tweet'].iloc[4],\"\\n\")\n",
    "#creating a function to process the data\n",
    "def data_processing(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"https\\S+|www\\S+http\\S+\", '', tweet, flags = re.MULTILINE)\n",
    "    tweet = re.sub(r'\\@w+|\\#','', tweet)\n",
    "    tweet = re.sub(r'[^\\w\\s]','',tweet)\n",
    "    tweet = re.sub(r'รฐ','',tweet)\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    filtered_tweets = [w for w in tweet_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c61eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.tweet = tweet_df['tweet'].apply(data_processing)\n",
    "tweet_df = tweet_df.drop_duplicates('tweet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizing(data):\n",
    "    tweet = [lemmarizer.lemmatize(word) for word in data]\n",
    "    return data\n",
    "tweet_df['tweet'] = tweet_df['tweet'].apply(lambda x: lemmatizing(x))\n",
    "# printing the data to see the effect of preprocessing\n",
    "print(tweet_df['tweet'].iloc[0],\"\\n\")\n",
    "print(tweet_df['tweet'].iloc[1],\"\\n\")\n",
    "print(tweet_df['tweet'].iloc[2],\"\\n\")\n",
    "print(tweet_df['tweet'].iloc[3],\"\\n\")\n",
    "print(tweet_df['tweet'].iloc[4],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf92f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.info()\n",
    "tweet_df['label'].value_counts()\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='label', data = tweet_df)fig = plt.figure(figsize=(7,7))\n",
    "colors = (\"red\", \"gold\")\n",
    "wp = {'linewidth':2, 'edgecolor':\"black\"}\n",
    "tags = tweet_df['label'].value_counts()\n",
    "explode = (0.1, 0.1)\n",
    "tags.plot(kind='pie',autopct = '%1.1f%%', shadow=True, colors = colors, startangle =90, \n",
    "         wedgeprops = wp, explode = explode, label='')\n",
    "plt.title('Distribution of sentiments')\n",
    "non_hate_tweets = tweet_df[tweet_df.label == 0]\n",
    "non_hate_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc344975",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join([word for word in non_hate_tweets['tweet']])\n",
    "plt.figure(figsize=(20,15), facecolor='None')\n",
    "wordcloud = WordCloud(max_words=500, width=1600, height=800).generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Most frequent words in non hate tweets', fontsize = 19)\n",
    "plt.show()\n",
    "neg_tweets = tweet_df[tweet_df.label == 1]\n",
    "neg_tweets.head()\n",
    "text = ' '.join([word for word in neg_tweets['tweet']])\n",
    "plt.figure(figsize=(20,15), facecolor='None')\n",
    "wordcloud = WordCloud(max_words=500, width=1600, height=800).generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Most frequent words in hate tweets', fontsize = 19)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a703471",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1,2)).fit(tweet_df['tweet'])\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\\n\".format(len(feature_names)))\n",
    "print(\"First 20 features: \\n{}\".format(feature_names[:20]))\n",
    "vect = TfidfVectorizer(ngram_range=(1,3)).fit(tweet_df['tweet'])\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\\n\".format(len(feature_names)))\n",
    "print(\"First 20 features: \\n{}\".format(feature_names[:20]))\n",
    "X = tweet_df['tweet']\n",
    "Y = tweet_df['label']\n",
    "X = vect.transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e62946",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "logreg_predict = logreg.predict(x_test)\n",
    "logreg_acc = accuracy_score(logreg_predict, y_test)\n",
    "print(\"Test accuarcy: {:.2f}%\".format(logreg_acc*100))\n",
    "style.use('classic')\n",
    "cm = confusion_matrix(y_test, logreg_predict, labels=logreg.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "param_grid = {'C':[100, 10, 1.0, 0.1, 0.01], 'solver' :['newton-cg', 'lbfgs','liblinear']}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv = 5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Best Cross validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "y_pred = grid.predict(x_test)\n",
    "logreg_acc = accuracy_score(y_pred, y_test)\n",
    "print(\"Test accuracy: {:.2f}%\".format(logreg_acc*100))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c54d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
