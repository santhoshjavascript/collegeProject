{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7380692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data and put into dataframe\n",
    "def read_data(csv):\n",
    "    return pd.read_csv(csv)\n",
    "data = read_data(\"risk_factors_cervical_cancer.csv\")\n",
    "data.replace(\"?\", np.nan, inplace=True)\n",
    "data.isna().sum()\n",
    "data = data.apply(pd.to_numeric)\n",
    "# remove columns that have less than half of the amount of rows as unknown\n",
    "# replace unknown values with mean of column\n",
    "def remove_unknowns(data):\n",
    "    i = 0\n",
    "    while i < data.shape[1]:\n",
    "        if data.count().iloc[i] < data.shape[0]/2:\n",
    "            data.drop(axis=1, labels=[data.columns[i]], inplace=True)\n",
    "            i -= 1\n",
    "        i += 1\n",
    "    column_means = round(data.mean())\n",
    "    data.fillna(column_means, inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_unknowns(data)\n",
    "sns.distplot(data[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"Number of sexual partners\"], kde_kws={'bw': .3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"First sexual intercourse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"Num of pregnancies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b043330",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"STDs: Number of diagnosis\"], kde_kws={'bw': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f00215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the risk factors are the features we are going to analyze\n",
    "features = (data.iloc[0:858, 0:30])\n",
    "\n",
    "#the four diagnoses are the target variables\n",
    "hinselmann = data[\"Hinselmann\"]\n",
    "schiller = data[\"Schiller\"]\n",
    "citology = data[\"Citology\"]\n",
    "biopsy = data[\"Biopsy\"]\n",
    "#define a dictionary of estimators for model\n",
    "estimators = {\n",
    "    'k-Nearest Neighbor': KNeighborsClassifier(), \n",
    "    'Support Vector Machine': LinearSVC(max_iter=1000000),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier()}\n",
    "#function that splits the data using percentage split (75% train 25% test)\n",
    "def split_data(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 3000)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data using percentage split\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = split_data(features, hinselmann)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = split_data(features, schiller)\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = split_data(features, citology)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = split_data(features, biopsy)\n",
    "# preprocess using MinMaxScaler\n",
    "def preprocessor(train, test):\n",
    "    scaler = MinMaxScaler().fit(train)\n",
    "    \n",
    "    #scale testing and training sets\n",
    "    X_train_scaled = scaler.transform(train)\n",
    "    X_test_scaled = scaler.transform(test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n",
    "#preprocess the data\n",
    "X_train_h_scaled, X_test_h_scaled = preprocessor(X_train_h, X_test_h)\n",
    "X_train_s_scaled, X_test_s_scaled = preprocessor(X_train_s, X_test_s)\n",
    "X_train_c_scaled, X_test_c_scaled = preprocessor(X_train_c, X_test_c)\n",
    "X_train_b_scaled, X_test_b_scaled = preprocessor(X_train_b, X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f27934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dictionary of feature selection methods\n",
    "feat_select_dict = {\"UNI\" : SelectKBest(score_func=f_classif, k = 3),\n",
    "                    \"MB\" : SelectFromModel(DecisionTreeRegressor(random_state = 3000)),\n",
    "                   \"RFE\" : RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 3)}\n",
    "#set up dataframes to hold results of selecting features vs using all of the features\n",
    "prelim_train_results = pd.DataFrame(index = [\"Acc_All\", \"Acc_UNI\", \"Acc_MB\", \"Acc_RFE\"])\n",
    "prelim_test_results = pd.DataFrame(index = [\"Acc_All\", \"Acc_UNI\", \"Acc_MB\", \"Acc_RFE\"])\n",
    "# Feature selection for each target variable and each selection method\n",
    "def feature_selection(feat_select_dict, xtrain, xtest, ytrain, ytest, target):\n",
    "    ml_model_all_train = LogisticRegression().fit(X=xtrain, y=ytrain)\n",
    "    ml_model_all_test = LogisticRegression().fit(X=xtest, y=ytest)\n",
    "    prelim_train_results.loc[\"Acc_All\", target] = ml_model_all_train.score(xtrain, ytrain)\n",
    "    prelim_test_results.loc[\"Acc_All\", target] = ml_model_all_test.score(xtest, ytest)\n",
    "    models = []\n",
    "    \n",
    "    for name, method in feat_select_dict.items():\n",
    "        model = method\n",
    "        model.fit(xtrain, ytrain)\n",
    "        xtrain_selected = model.transform(xtrain)\n",
    "        xtest_selected = model.transform(xtest)\n",
    "        models.append(model)\n",
    "        ml_model_selected_train = LogisticRegression().fit(X=xtrain_selected, y=ytrain)\n",
    "        ml_model_selected_test = LogisticRegression().fit(X=xtest_selected, y=ytest)\n",
    "        prelim_train_results.loc[\"Acc_\" + name, target] = ml_model_selected_train.score(xtrain_selected, ytrain)\n",
    "        prelim_test_results.loc[\"Acc_\" + name, target] = ml_model_selected_test.score(xtest_selected, ytest)\n",
    "    return prelim_train_results, prelim_test_results, models\n",
    "prelim_train_results, prelim_test_results, models_h = feature_selection(feat_select_dict, X_train_h_scaled, X_test_h_scaled, y_train_h, y_test_h, \"Hinselmann\")\n",
    "prelim_train_results, prelim_test_results, models_s = feature_selection(feat_select_dict, X_train_s_scaled, X_test_s_scaled, y_train_s, y_test_s, \"Shiller\")\n",
    "prelim_train_results, prelim_test_results, models_c = feature_selection(feat_select_dict, X_train_c_scaled, X_test_c_scaled, y_train_c, y_test_c, \"Citology\")\n",
    "prelim_train_results, prelim_test_results, models_b =  feature_selection(feat_select_dict, X_train_b_scaled, X_test_b_scaled, y_train_b, y_test_b, \"Biopsy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "#Selected features extraction\n",
    "def extract_features(model):\n",
    "    list = [i for i, val in enumerate(model.get_support()) if val]\n",
    "    index=0\n",
    "    while index < 3:\n",
    "        print(features.columns[list][index])\n",
    "        features_list.append(features.columns[list][index])\n",
    "        index += 1\n",
    "\n",
    "    return features_list\n",
    "extract_features(models_h[0])\n",
    "extract_features(models_h[1])\n",
    "extract_features(models_h[2])\n",
    "extract_features(models_s[0])\n",
    "extract_features(models_s[1])\n",
    "extract_features(models_s[2])\n",
    "extract_features(models_c[0])\n",
    "extract_features(models_c[1])\n",
    "extract_features(models_c[2])\n",
    "extract_features(models_b[0])\n",
    "extract_features(models_b[1])\n",
    "features_list = extract_features(models_b[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a37dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates in the list\n",
    "features_list = list(set(features_list))\n",
    "#remove columns that are not the selected features\n",
    "def select_features_in_data(x, features, columns_list):\n",
    "    x_selected = pd.DataFrame(x, columns = features)\n",
    "    x_selected = x_selected.drop(columns = [col for col in x_selected if col not in columns_list])\n",
    "    return x_selected\n",
    "X_train_h_selected = select_features_in_data(X_train_h_scaled, list(features.columns), features_list)\n",
    "X_test_h_selected = select_features_in_data(X_test_h_scaled, list(features.columns), features_list)\n",
    "X_train_s_selected = select_features_in_data(X_train_s_scaled, list(features.columns), features_list)\n",
    "X_test_s_selected = select_features_in_data(X_test_s_scaled, list(features.columns), features_list)\n",
    "X_train_c_selected = select_features_in_data(X_train_c_scaled, list(features.columns), features_list)\n",
    "X_test_c_selected = select_features_in_data(X_test_c_scaled, list(features.columns), features_list)\n",
    "X_train_b_selected = select_features_in_data(X_train_b_scaled, list(features.columns), features_list)\n",
    "X_test_b_selected = select_features_in_data(X_test_b_scaled, list(features.columns), features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab2335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the four target variables in a dataframe\n",
    "features_list.append(\"Hinselmann\")\n",
    "features_list.append(\"Schiller\")\n",
    "features_list.append(\"Citology\")\n",
    "features_list.append(\"Biopsy\")\n",
    "\n",
    "#show dataframe of selected data\n",
    "selected_data = data.drop(columns = [col for col in data if col not in features_list])\n",
    "\n",
    "#CLEANING: clean up strings so they can used as numbers\n",
    "for columns in selected_data:\n",
    "    selected_data[columns] = pd.to_numeric(selected_data[columns])\n",
    "selected_feature_data = [X_train_h_selected, X_test_h_selected, X_train_s_selected, X_test_s_selected , X_train_c_selected, X_test_c_selected, \n",
    "                X_train_b_selected, X_test_b_selected]\n",
    "for df in selected_feature_data:\n",
    "    df.drop(\"Dx:Cancer\", axis=1, inplace = True)\n",
    "\n",
    "    \n",
    "hypothesis_data = data[[\"Age\", \"Number of sexual partners\", \"First sexual intercourse\", \"Num of pregnancies\", \"Smokes (years)\", \"Hormonal Contraceptives (years)\", \"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69677b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are doing T Test, we have to make sure that all the columns in our dataset are binary\n",
    "# to transfer the columns into binary values\n",
    "import numpy as np \n",
    "\n",
    "age_range_0 = np.arange(12, 40)\n",
    "age_range_1 = np.arange(39, 85)\n",
    "\n",
    "sex_part_0 = np.arange(0, 5)\n",
    "sex_part_1 = np.arange(5, 29)\n",
    "\n",
    "first_sex_0 = np.arange(16)\n",
    "first_sex_1 = np.arange(15, 33)\n",
    "\n",
    "num_preg_0 = np.arange(4)\n",
    "num_preg_1 = np.arange(3, 12)\n",
    "\n",
    "#CLEANING: clean up strings so they can used as numbers\n",
    "for columns in selected_data:\n",
    "    selected_data[columns] = pd.to_numeric(selected_data[columns])\n",
    "    \n",
    "def trans_to_binary(data):\n",
    "    smoke_range = data[\"Smokes (years)\"]\n",
    "\n",
    "    for years in smoke_range:\n",
    "        if years < 1:\n",
    "            data[\"Smokes (years)\"].replace(years, 0, inplace=True)\n",
    "        else:\n",
    "            data[\"Smokes (years)\"].replace(years, 1, inplace=True)\n",
    "        \n",
    "    hor_range = data['Hormonal Contraceptives (years)']\n",
    "\n",
    "    for years in hor_range:\n",
    "        if years < 1:\n",
    "            data['Hormonal Contraceptives (years)'].replace(years, 0, inplace=True)\n",
    "        else:\n",
    "            data['Hormonal Contraceptives (years)'].replace(years, 1, inplace=True)\n",
    "    data[\"Age\"].replace(age_range_0, 0, inplace=True)\n",
    "    data[\"Age\"].replace(age_range_1, 1, inplace=True)\n",
    "    data[\"Number of sexual partners\"].replace(sex_part_0, 0, inplace=True)\n",
    "    data[\"Number of sexual partners\"].replace(sex_part_1, 1, inplace=True)\n",
    "    data[\"First sexual intercourse\"].replace(first_sex_0, 0, inplace=True)\n",
    "    data[\"First sexual intercourse\"].replace(first_sex_1, 1, inplace=True)\n",
    "    data[\"Num of pregnancies\"].replace(num_preg_0, 0, inplace=True)\n",
    "    data[\"Num of pregnancies\"].replace(num_preg_1, 1, inplace=True)\n",
    "    return data\n",
    "\n",
    "hp_test = trans_to_binary(hypothesis_data)\n",
    "hp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_test(data,IV,DV):\n",
    "    catego = [x[1] for x in data.groupby(IV)[DV]]\n",
    "    f_statistics, p_values = stats.f_oneway( * catego)\n",
    "    df1 = len(data.groupby(IV)[DV]) - 1\n",
    "    df2 = sum([len(x[1])-1 for x in data.groupby(IV)[DV]])\n",
    "    print(str(IV) + \" ---- F-test\")\n",
    "    print(\"------------------------------\" + \"\\n\")\n",
    "    print(\"F(\"+format(df1,'d')+\",\"+format(df2,'d')+\") = \" + format(f_statistics,'.2f') + \" , p = \"+format(p_values,'.4f')+\"\\n\")\n",
    "    print(\"------------------------------\" + \"\\n\")\n",
    "\n",
    "def t_test(data,IV,DV):\n",
    "    results = stats.ttest_rel(data[IV],data[DV])\n",
    "    #t value\n",
    "    tstatistic = results[0]\n",
    "    #p value in scientific notation\n",
    "    pvalue = results[1]\n",
    "    print(str(IV) + \" ---- t-test\")\n",
    "    print(\"------------------------------\" + \"\\n\")\n",
    "    print(\"t-value =\"+format(tstatistic,'.2f')+\"   pvalue = \"+format(pvalue,'.10f')+\"\\n\")\n",
    "    if(pvalue<0.05):\n",
    "        print(\"pvalue is not significant\\n\")\n",
    "        print(\"------------------------------\" + \"\\n\")\n",
    "\n",
    "    else:\n",
    "        print(\"pvalue is significant\\n\")\n",
    "        print(\"------------------------------\" + \"\\n\")\n",
    "\n",
    "def check_levene(data,IV,DV):\n",
    "    catego = [x[1] for x in data.groupby(IV)[DV]]\n",
    "    levene_results = stats.levene( * catego)\n",
    "    print(str(IV) +  \"\\n\" + \" Assumption of Equality of Variances:\")\n",
    "    print(\"\\t\", end = \"\")\n",
    "    print(levene_results)\n",
    "    if (levene_results[1] > 0.05):\n",
    "        print(\"\\t\\t\"+\"Assumption is met. p > .05\" + \"\\n\")\n",
    "    else:\n",
    "        print(\"\\t\\t\"+\"Assumption is not met, p < 0.05\" + \"\\n\")\n",
    "\n",
    "        \n",
    "def check_shapiro(data,IV,DV):\n",
    "    shapiro = data.groupby(IV)[DV].agg(lambda x : stats.shapiro(x))\n",
    "    print(str(IV) +  \"\\n\" + \"Assumption of Normality:\")\n",
    "    for i in range (shapiro.size):\n",
    "        print(\"\\n\",end = \"\")\n",
    "        print(shapiro.index[i], end = \" : \")\n",
    "        print(end = \"\")\n",
    "        print(shapiro.iloc[i])\n",
    "        if(shapiro.iloc[i][1]>0.05):\n",
    "            print(\"\\t\\t\"+\"Assumption is met. p > .05\"+  \"\\n\"+  \"\\n\")\n",
    "        else:\n",
    "            print(\"\\t\\t\"+\"Assumption is not met, p < 0.05\"+  \"\\n\"+  \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target \"Hinselmann\"\n",
    "features = (hp_test.iloc[0:858, 0:6])\n",
    "for fea in features:\n",
    "    f_test(hp_test, fea, \"Hinselmann\")\n",
    "    t_test(hp_test, fea, \"Hinselmann\")\n",
    "    check_levene(hp_test, fea, \"Hinselmann\")\n",
    "    check_shapiro(hp_test, fea, \"Hinselmann\")\n",
    "# for target \"Schiller\"\n",
    "features = (hp_test.iloc[0:858, 0:6])\n",
    "for fea in features:\n",
    "    f_test(hp_test, fea, \"Schiller\")\n",
    "    t_test(hp_test, fea, \"Schiller\")\n",
    "    check_levene(hp_test, fea, \"Schiller\")\n",
    "    check_shapiro(hp_test, fea, \"Schiller\")\n",
    "# for target \"Citology\"\n",
    "features = (hp_test.iloc[0:858, 0:6])\n",
    "for fea in features:\n",
    "    f_test(hp_test, fea, \"Citology\")\n",
    "    t_test(hp_test, fea, \"Citology\")\n",
    "    check_levene(hp_test, fea, \"Citology\")\n",
    "    check_shapiro(hp_test, fea, \"Citology\")\n",
    "    \n",
    "# for target \"Biopsy\"\n",
    "features = (hp_test.iloc[0:858, 0:6])\n",
    "for fea in features:\n",
    "    f_test(hp_test, fea, \"Biopsy\")\n",
    "    t_test(hp_test, fea, \"Biopsy\")\n",
    "    check_levene(hp_test, fea, \"Biopsy\")\n",
    "    check_shapiro(hp_test, fea, \"Biopsy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame to hold all results\n",
    "df_accuracy = pd.DataFrame(index=[\"Accuracy-Selected\", \"Accuracy-All\"])\n",
    "df_f1 = pd.DataFrame(index=[\"F1 Score-Selected\", \"F1 Score-All\"])\n",
    "#function that applies the algorithms to the data\n",
    "def apply_algorithms(target, features, x_train, x_test, ytrain, ytest):\n",
    "    for estimator_name, estimator_object in estimators.items():\n",
    "        #fit scaled sets to model\n",
    "        estimator_object.fit(X=x_train, y=ytrain)\n",
    "        #make predictions on the test set\n",
    "        predicted = estimator_object.predict(X=x_test)\n",
    "        expected = ytest\n",
    "        #display classification metric results\n",
    "        accuracy = estimator_object.score(x_test, ytest)\n",
    "        f1score = f1_score(y_true=expected, y_pred=predicted, average=None)[0]\n",
    "        df_accuracy.loc[\"Accuracy-\" + features, target + \": \" + estimator_name] = accuracy\n",
    "        df_f1.loc[\"F1 Score-\" + features, target + \": \" + estimator_name] = f1score\n",
    "        print(target)\n",
    "        print(estimator_name + \": \\n\\t\" + \"Prediction accuracy on the test data:\", f\"{accuracy:.2%}\" + \"\\n\")\n",
    "        print(\"\\tF1 Score: \" + str(f1score) + \"\\n\")\n",
    "        \n",
    "#results\n",
    "print('TEST RESULTS WHEN ONLY SELECTED FEATURES USED:')\n",
    "print('___________________________________________\\n')\n",
    "print('With Selected Features')\n",
    "apply_algorithms(\"Hinselmann\", \"Selected\", X_train_h_selected, X_test_h_selected, y_train_h, y_test_h)\n",
    "apply_algorithms(\"Schiller\", \"Selected\", X_train_s_selected, X_test_s_selected, y_train_s, y_test_s)\n",
    "apply_algorithms(\"Citology\", \"Selected\", X_train_c_selected, X_test_c_selected, y_train_c, y_test_c)\n",
    "apply_algorithms(\"Biopsy\", \"Selected\", X_train_b_selected, X_test_b_selected, y_train_b, y_test_b)\n",
    "print('\\nTEST RESULTS WHEN ALL FEATURES USED:')\n",
    "print('____________________________________\\n')\n",
    "print('With All Features')\n",
    "apply_algorithms(\"Hinselmann\", \"All\", X_train_h_scaled, X_test_h_scaled, y_train_h, y_test_h)\n",
    "apply_algorithms(\"Schiller\", \"All\", X_train_s_scaled, X_test_s_scaled, y_train_s, y_test_s)\n",
    "apply_algorithms(\"Citology\", \"All\", X_train_c_scaled, X_test_c_scaled, y_train_c, y_test_c)\n",
    "apply_algorithms(\"Biopsy\", \"All\", X_train_b_scaled, X_test_b_scaled, y_train_b, y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average by algorithm\n",
    "def calc_avg_for_algorithms(df, algorithm):\n",
    "    list = [column for column in df.columns.tolist() if algorithm in column]\n",
    "    return pd.DataFrame(data = df[list]).mean(axis = 1)\n",
    "\n",
    "average_accuracies = {\"KNN\" : calc_avg_for_algorithms(df_accuracy, \"Neighbor\"),\n",
    "            \"SVM\": calc_avg_for_algorithms(df_accuracy, \"Support\"),\n",
    "            \"Logistic Regression\": calc_avg_for_algorithms(df_accuracy, \"Logistic\"),\n",
    "            \"Decision Tree\": calc_avg_for_algorithms(df_accuracy, \"Decision Tree\")}\n",
    "pd.DataFrame(average_accuracies)\n",
    "average_f1s = {\"KNN\" : calc_avg_for_algorithms(df_f1, \"Neighbor\"),\n",
    "            \"SVM\": calc_avg_for_algorithms(df_f1, \"Support\"),\n",
    "            \"Logistic Regression\": calc_avg_for_algorithms(df_f1, \"Logistic\"),\n",
    "            \"Decision Tree\": calc_avg_for_algorithms(df_f1, \"Decision Tree\")}\n",
    "\n",
    "#Create a confusion matrix to evaluate performance given the training and test data\n",
    "def confusion_matrix(xtrain, xtest, ytrain, ytest):\n",
    "    \n",
    "    cms = []\n",
    "    \n",
    "    for estimator_name, estimator_object in estimators.items():\n",
    "        \n",
    "        #fit scaled sets to model\n",
    "        estimator_object.fit(xtrain, ytrain)\n",
    "        \n",
    "        #make predictions on the test set\n",
    "        predicted = estimator_object.predict(xtest)\n",
    "        expected = ytest \n",
    "        \n",
    "        pred_log = estimator_object.predict(xtest)\n",
    "\n",
    "        cm = metrics.confusion_matrix(ytest, pred_log)\n",
    "        cms.append(cm)\n",
    "\n",
    "        print(estimator_name + \": \\n\" + metrics.classification_report(ytest,pred_log,digits=2))\n",
    "        \n",
    "        # the accuracy score \n",
    "        print(metrics.accuracy_score(ytest,pred_log))\n",
    "        \n",
    "    return cms\n",
    "\n",
    "#Create a heatmap to visualize the confusion matrix of the given algorithm's performance\n",
    "def heatmap(confusion_matrix, algorithm):\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(confusion_matrix, annot=True,  fmt='.2f', xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"])\n",
    "    plt.ylabel('True label',fontsize=16)\n",
    "    plt.xlabel('Predicted label',fontsize=16)\n",
    "    plt.title(algorithm)\n",
    "    \n",
    "heatmap(cm_h[0], \"K-Nearest Neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize the LogisticRegression algorithm\n",
    "param_grid = {'C':[.001, .01, .1, 1, 10, 100]}\n",
    "def grid_search_lr(target, xtrain, xtest, ytrain, ytest):\n",
    "    \n",
    "    grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "    \n",
    "    grid_search.fit(X=xtrain, y=ytrain)\n",
    "    \n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Training set score with best parameters\", grid_search.best_score_)\n",
    "    print(\"Test set score with best parameters:\", grid_search.score(xtest, ytest))\n",
    "\n",
    "grid_search_lr(hinselmann, X_train_h_selected, X_test_h_selected, y_train_h, y_test_h)\n",
    "\n",
    "#define estimators to be Logistic Regression and Decision Tree algorithm\n",
    "estimators = {\"Logistic Regression\" : LogisticRegression(C = .001), \"Decision Tree\" : DecisionTreeClassifier(max_depth=1, min_samples_leaf=1, min_samples_split=2)}\n",
    "#results for tuned Logistic Regression and Decision Tree Algorithm\n",
    "#test with selected features\n",
    "print('With Selected Features')\n",
    "apply_algorithms(\"Hinselmann\", \"Selected\", X_train_h_selected, X_test_h_selected, y_train_h, y_test_h)\n",
    "apply_algorithms(\"Schiller\", \"Selected\", X_train_s_selected, X_test_s_selected, y_train_s, y_test_h)\n",
    "apply_algorithms(\"Citology\", \"Selected\", X_train_c_selected, X_test_c_selected, y_train_c, y_test_c)\n",
    "apply_algorithms(\"Biopsy\", \"Selected\", X_train_b_selected, X_test_b_selected, y_train_b, y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43c1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
